{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather news "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data essentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# custom helper functions\n",
    "import custom_helper as ps\n",
    "\n",
    "# API\n",
    "from pynytimes import NYTAPI\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct search terms \n",
    "## Define topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 37 negative and 28 positive topics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scandal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greenwashing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corruption</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fraud</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bribe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          topic  positive\n",
       "0       scandal         0\n",
       "1  greenwashing         0\n",
       "2    corruption         0\n",
       "3         fraud         0\n",
       "4         bribe         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_negative = ['scandal', 'greenwashing', 'corruption', 'fraud', \n",
    "                   'bribe', 'tax', 'forced', 'harassment', 'violation', \n",
    "                   'illegal', 'conflict', 'weapons', 'pollution',\n",
    "                   'inequality', 'discrimination', 'sexism', 'racist', \n",
    "                   'intransparent', 'nontransparent', 'breach', 'lawsuit', \n",
    "                   'unfair', 'bad', 'problem', 'hate', 'issue', 'controversial', \n",
    "                  'strike', 'scam', 'trouble', 'controversy', 'mismanagement', \n",
    "                  'crisis', 'turmoil', 'shock', 'whistleblow', 'dispute']\n",
    "\n",
    "topics_positive =  ['green', 'sustainable', 'positive', 'best', 'good', \n",
    "                    'social', 'charity', 'ethical', 'renewable', 'carbon neutral', \n",
    "                   'equitable', 'ecological', 'efficient', 'improve', 'cooperative', \n",
    "                   'beneficial', 'collaborative', 'productive', 'leader', \n",
    "                   'donate', 'optimal', 'favorable', 'desirable', 'resilient', \n",
    "                   'robust', 'reasonable', 'strong', 'organic']\n",
    "\n",
    "print(\"Defined {} negative and {} positive topics\".format(len(topics_negative), len(topics_positive)))\n",
    "\n",
    "\n",
    "# create df with topics and label\n",
    "df_topics_neg = pd.DataFrame({'topic':topics_negative, 'positive': 0})\n",
    "df_topics_pos = pd.DataFrame({'topic':topics_positive, 'positive': 1})\n",
    "df_topics = pd.concat([df_topics_neg, df_topics_pos]).reset_index(drop=True)\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get firm names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_name_raw</th>\n",
       "      <th>sector</th>\n",
       "      <th>firm_name_processed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>3M Company</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABT</th>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>AbbVie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABMD</th>\n",
       "      <td>ABIOMED Inc</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>ABIOMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <td>Accenture plc</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              firm_name_raw                  sector  firm_name_processed\n",
       "ticker                                                                  \n",
       "MMM              3M Company             Industrials                   3M\n",
       "ABT     Abbott Laboratories             Health Care  Abbott Laboratories\n",
       "ABBV            AbbVie Inc.             Health Care               AbbVie\n",
       "ABMD            ABIOMED Inc             Health Care              ABIOMED\n",
       "ACN           Accenture plc  Information Technology            Accenture"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def regex_strip_legalname(raw_names):\n",
    "    \"\"\"Removes legal entity, technical description or firm type from firm name\n",
    "    \n",
    "    Input\n",
    "        raw_names: list of strings with firm names\n",
    "        \n",
    "    Return\n",
    "        list of strings: firm names without legal description \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    pattern = r\"(\\s|\\.|\\,|\\&)*(\\.com|Enterprise|Worldwide|Int\\'l|N\\.V\\.|LLC|Co\\b|Inc\\b|Corp\\w*|Group\\sInc|Group|Company|Holdings\\sInc|\\WCo(\\s|\\.)|plc|Ltd|Int'l\\.|Holdings|\\(?Class\\s\\w+\\)?)\\.?\\W?\"\n",
    "    stripped_names = [re.sub(pattern,'', n) for n in raw_names]\n",
    "    \n",
    "    return stripped_names\n",
    "\n",
    "# get firm S&P500 from Wikipedia\n",
    "keep_columns = ['Symbol','Security', 'GICS Sector']\n",
    "df_sp500_wiki = ps.get_firms_sp500().loc[:,keep_columns]\n",
    "\n",
    "# rename column, set ticker as index\n",
    "df_sp500_wiki= df_sp500_wiki.rename(columns={'Symbol': 'ticker', 'Security': 'firm_name_raw', 'GICS Sector': 'sector'})\\\n",
    "    .set_index('ticker')\n",
    "\n",
    "# process firm names (remove legal entity)\n",
    "df_sp500_wiki['firm_name_processed'] = regex_strip_legalname(list(df_sp500_wiki.firm_name_raw))\n",
    "\n",
    "# drop duplicate firm names (after processing)\n",
    "df_sp500_wiki.drop_duplicates(subset='firm_name_processed', inplace=True)\n",
    "\n",
    "df_sp500_wiki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct query keywords\n",
    "> **Desired table** where 1 row = 1 search term\n",
    "\n",
    "> | topic | firm_name | ...| search_term | positive (dummy)\n",
    "> | --- | --- | --- | ---| --- \n",
    "\n",
    "> *search_term* is a pairwise combination of *topic* and *firm_name*\n",
    "> *positive* is a binary variable that indicates a positive topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>positive</th>\n",
       "      <th>firm_name_raw</th>\n",
       "      <th>sector</th>\n",
       "      <th>firm_name_processed</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>scandal</td>\n",
       "      <td>0</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>3M</td>\n",
       "      <td>scandal 3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>greenwashing</td>\n",
       "      <td>0</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>3M</td>\n",
       "      <td>greenwashing 3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>corruption</td>\n",
       "      <td>0</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>3M</td>\n",
       "      <td>corruption 3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>fraud</td>\n",
       "      <td>0</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>3M</td>\n",
       "      <td>fraud 3M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>bribe</td>\n",
       "      <td>0</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>3M</td>\n",
       "      <td>bribe 3M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               topic  positive firm_name_raw       sector firm_name_processed  \\\n",
       "ticker                                                                          \n",
       "MMM          scandal         0    3M Company  Industrials                  3M   \n",
       "MMM     greenwashing         0    3M Company  Industrials                  3M   \n",
       "MMM       corruption         0    3M Company  Industrials                  3M   \n",
       "MMM            fraud         0    3M Company  Industrials                  3M   \n",
       "MMM            bribe         0    3M Company  Industrials                  3M   \n",
       "\n",
       "            search_term  \n",
       "ticker                   \n",
       "MMM          scandal 3M  \n",
       "MMM     greenwashing 3M  \n",
       "MMM       corruption 3M  \n",
       "MMM            fraud 3M  \n",
       "MMM            bribe 3M  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand firm names for each topic\n",
    "df_sp500_expanded = df_sp500_wiki.iloc[np.repeat(np.arange(len(df_sp500_wiki)), len(df_topics))]\n",
    "# expand topics for each firm \n",
    "df_topics_expanded = df_topics.iloc[list(np.arange(len(df_topics)))*len(df_sp500_wiki)]\\\n",
    "    .set_index(df_sp500_expanded.index)\n",
    "\n",
    "# create search keywords as a combintation of firm name + topic\n",
    "search_terms = pd.DataFrame({'search_term':[i+' '+j for j in df_sp500_wiki.firm_name_processed for i in df_topics.topic]})\\\n",
    "    .set_index(df_sp500_expanded.index)\n",
    "\n",
    "# merge topics, firm names, and search terms into 1 df\n",
    "df_query_input = pd.concat([df_topics_expanded, df_sp500_expanded, search_terms], axis=1)\n",
    "\n",
    "df_query_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google News\n",
    "\n",
    "##  Query functions\n",
    "### I. `get_news()` retrieves news for a keyword\n",
    "### II. `query_news()` loops over list of keywords, handles potential errors and stores query results as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def sleep_countdown(duration, print_step=2):\n",
    "    \"\"\"Sleep for certain duration and print remaining time in steps of print_step\n",
    "\n",
    "    Input\n",
    "    duration: duration of timeout (int)\n",
    "    print_step: steps to print countdown (int)\n",
    "\n",
    "    Return \n",
    "    None\n",
    "    \"\"\"\n",
    "    for i in range(duration,0,-print_step):\n",
    "        sys.stdout.write(str(i)+' ')\n",
    "        sys.stdout.flush()\n",
    "        sleep(print_step)\n",
    "    sys.stdout.write('cont.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from GoogleNews import GoogleNews\n",
    "import custom_helper\n",
    "\n",
    "def get_news(keyword, until_page=10, keep_columns=['title', 'date', 'desc'], timeout=10):\n",
    "    \"\"\"Retrieve news for keyword for the first specified number of result pages\n",
    "        within the period until 1 year ago\n",
    "        \n",
    "    Input\n",
    "        keyword to look up news for\n",
    "    \n",
    "    Return\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    ## define 1 year timespan with datestrings \n",
    "    # today's date\n",
    "    date_today = date.today().strftime(\"%m/%d/%Y\")\n",
    "    # date 1 year ago\n",
    "    date_1year_ago = ps.date_add_year(date.today(), -1).strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    ## Google news query\n",
    "    # init googlenews object with US-en country-language setting\n",
    "    googlenews=GoogleNews(lang='en-US&gl=US&ceid=US:en', start=date_1year_ago, end=date_today)    \n",
    "    \n",
    "    # retrieve search news for keyword\n",
    "    googlenews.search(keyword)\n",
    "    \n",
    "    # get results for each page \n",
    "    for p in range(until_page):\n",
    "        print(\"Page {} for {}\".format(p, keyword))\n",
    "        googlenews.getpage(p)\n",
    "        sleep_countdown(timeout, print_step=2)\n",
    "    \n",
    "    # store results in df\n",
    "    result = pd.DataFrame(googlenews.result())\n",
    "    \n",
    "    \n",
    "    ## process result data\n",
    "    # drop duplicates\n",
    "    result.drop_duplicates(inplace=True)\n",
    "    # keep specified columns\n",
    "    result = result[keep_columns]\n",
    "    # add column with keyword\n",
    "    result['search_term'] = keyword\n",
    "    \n",
    "    # clear google news cache\n",
    "    googlenews.clear()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def query(lst, max_retries=1, idx_unsuccessful=list(), until_page=5, timeout=20) :\n",
    "    \"\"\"Handle failed query and handle raised exceptions\n",
    "    \n",
    "    Input\n",
    "        lst: list with keywords for which to retrieve news\n",
    "        max_retries: number of maximum retries\n",
    "        until_page: maximum number of retrievd news page\n",
    "        \n",
    "    \n",
    "    Return\n",
    "        Inidces where max retries were reached\n",
    "    \"\"\"    \n",
    "    for i in lst:\n",
    "        # retry until max_retries reached\n",
    "        for attempt in range(max_retries):        \n",
    "            try:\n",
    "                df_result = get_news(i, until_page=until_page, timeout=timeout)\n",
    "        \n",
    "            # handle query error\n",
    "            except Exception as e:\n",
    "                timeout += 5\n",
    "                print(\"\\t>>>EXCEPTION at {}: {}. Set timeout to {}\\n\".format(i, e, timeout))\n",
    "                sleep_countdown(10)\n",
    "                \n",
    "            \n",
    "            # query was successful: store results\n",
    "            else:\n",
    "                stamp = ps.timestamp_now()\n",
    "                # merge news dataframes and export query results\n",
    "                ps.make_csv(df_result, \"news.csv\", 'data/news', append=True)\n",
    "                break\n",
    "\n",
    "        # max_retries reached: store index of unsuccessful query\n",
    "        else:\n",
    "            ps.make_csv(pd.DataFrame([i]), \"unsuccessful_queries.csv\", 'data/news', append=True)\n",
    "            print(\"i: {} appended to idx_unsuccessful\\n\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run query for all search_terms\n",
    "> **Issue**: Possibly rate limit exceeded, nothing is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 8 6 4 2 cont.Page 0 for conflict 3M\n",
      "10 8 6 4 2 cont.Page 1 for conflict 3M\n",
      "\t>>>EXCEPTION at conflict 3M: \"None of [Index(['title', 'date', 'desc'], dtype='object')] are in the [columns]\". Set timeout to 15\n",
      "\n",
      "10 8 6 4 2 cont.Path created: data/news/unsuccessful_queries.csv\n",
      "i: conflict 3M appended to idx_unsuccessful\n",
      "\n",
      "15 13 11 9 7 5 3 1 cont.Page 0 for weapons 3M\n",
      "15 13 11 9 7 5 3 1 cont.Page 1 for weapons 3M\n",
      "\t>>>EXCEPTION at weapons 3M: \"None of [Index(['title', 'date', 'desc'], dtype='object')] are in the [columns]\". Set timeout to 20\n",
      "\n",
      "10 8 6 4 2 cont.Path created: data/news/unsuccessful_queries.csv\n",
      "i: weapons 3M appended to idx_unsuccessful\n",
      "\n",
      "20 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-364-242ed6b67922>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mquery_news\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_query_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muntil_page\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-363-07361f5645e7>\u001b[0m in \u001b[0;36mquery_news\u001b[1;34m(lst, max_retries, idx_unsuccessful, until_page, timeout)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mdf_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_news\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muntil_page\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muntil_page\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m# handle query error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-361-8e8f88529320>\u001b[0m in \u001b[0;36mget_news\u001b[1;34m(keyword, until_page, keep_columns, timeout)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# get results for each page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muntil_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0msleep_countdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Page {} for {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mgooglenews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetpage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-358-68d1b90016fd>\u001b[0m in \u001b[0;36msleep_countdown\u001b[1;34m(duration, print_step)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprint_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cont.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query(df_query_input.search_term[10:15], until_page=2, timeout=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./data/news/news.csv does not exist: './data/news/news.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-317-e615a0b77694>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## merge query input with query results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# import news data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_news\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/news/news.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# merge with query input for ticker and firm name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_query_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_news\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'search_term'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File ./data/news/news.csv does not exist: './data/news/news.csv'"
     ]
    }
   ],
   "source": [
    "## merge query input with query results\n",
    "# import news data\n",
    "df_news = pd.read_csv('./data/news/news.csv')\n",
    "# merge with query input for ticker and firm name\n",
    "df_query_input.merge(df_news, how='outer', on='search_term', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYTimes API\n",
    "\n",
    "* all nytimes article accessible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize API\n",
    "https://pypi.org/project/pynytimes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pynytimes import NYTAPI\n",
    "\n",
    "file_api_key = open('nytimes_api_key.txt', 'r') \n",
    "api_key = file_api_key.readlines()[0]\n",
    "nyt = NYTAPI(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Article search (beta)\n",
    "from datetime import datetime\n",
    "\n",
    "articles = nyt.article_search(\n",
    "    query = \"3M\",\n",
    "    results = 50,\n",
    "    dates = {\n",
    "        \"begin\": datetime(2019, 1, 31)\n",
    "    },\n",
    "    options = {\n",
    "        \"sort\": \"relevance\",\n",
    "        \"sources\": [\n",
    "            \"New York Times\",\n",
    "            \"AP\",\n",
    "            \"Reuters\",\n",
    "            \"International Herald Tribune\"\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.nytimes.com/video/us/elections/100000007293558/michelle-obama-speaks-dnc.html'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pd.DataFrame(articles)\n",
    "articles.iloc[0,:][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>subsection</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>uri</th>\n",
       "      <th>byline</th>\n",
       "      <th>item_type</th>\n",
       "      <th>updated_date</th>\n",
       "      <th>created_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>material_type_facet</th>\n",
       "      <th>kicker</th>\n",
       "      <th>des_facet</th>\n",
       "      <th>org_facet</th>\n",
       "      <th>per_facet</th>\n",
       "      <th>geo_facet</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>short_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>health</td>\n",
       "      <td></td>\n",
       "      <td>Pediatrics Group Offers ‘Long Overdue’ Apology...</td>\n",
       "      <td>The American Academy of Pediatrics recently jo...</td>\n",
       "      <td>https://www.nytimes.com/2020/08/20/health/pedi...</td>\n",
       "      <td>nyt://article/0e1e1c34-87f0-589c-b490-2451da15...</td>\n",
       "      <td>By Emma Goldberg</td>\n",
       "      <td>Article</td>\n",
       "      <td>2020-08-20T05:00:22-04:00</td>\n",
       "      <td>2020-08-20T05:00:22-04:00</td>\n",
       "      <td>2020-08-20T05:00:22-04:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[Discrimination, Black People, Race and Ethnic...</td>\n",
       "      <td>[American Academy of Pediatrics, American Medi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Southern States (US)]</td>\n",
       "      <td>[{'url': 'https://static01.nyt.com/images/2020...</td>\n",
       "      <td>https://nyti.ms/3ghMlzo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>health</td>\n",
       "      <td></td>\n",
       "      <td>This Trawler’s Haul: Evidence That Antibodies ...</td>\n",
       "      <td>Three crew members aboard were spared when the...</td>\n",
       "      <td>https://www.nytimes.com/2020/08/19/health/coro...</td>\n",
       "      <td>nyt://article/de93d5ac-7ea4-543d-817d-ba63e0ea...</td>\n",
       "      <td>By Apoorva Mandavilli</td>\n",
       "      <td>Article</td>\n",
       "      <td>2020-08-19T23:45:36-04:00</td>\n",
       "      <td>2020-08-19T15:32:15-04:00</td>\n",
       "      <td>2020-08-19T15:32:15-04:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[Coronavirus (2019-nCoV), Antibodies, Boats an...</td>\n",
       "      <td>[Hutchinson, Fred, Cancer Research Center, Abb...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Seattle (Wash)]</td>\n",
       "      <td>[{'url': 'https://static01.nyt.com/images/2020...</td>\n",
       "      <td>https://nyti.ms/3aFM0W4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  section subsection                                              title  \\\n",
       "0  health             Pediatrics Group Offers ‘Long Overdue’ Apology...   \n",
       "1  health             This Trawler’s Haul: Evidence That Antibodies ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The American Academy of Pediatrics recently jo...   \n",
       "1  Three crew members aboard were spared when the...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.nytimes.com/2020/08/20/health/pedi...   \n",
       "1  https://www.nytimes.com/2020/08/19/health/coro...   \n",
       "\n",
       "                                                 uri                 byline  \\\n",
       "0  nyt://article/0e1e1c34-87f0-589c-b490-2451da15...       By Emma Goldberg   \n",
       "1  nyt://article/de93d5ac-7ea4-543d-817d-ba63e0ea...  By Apoorva Mandavilli   \n",
       "\n",
       "  item_type               updated_date               created_date  \\\n",
       "0   Article  2020-08-20T05:00:22-04:00  2020-08-20T05:00:22-04:00   \n",
       "1   Article  2020-08-19T23:45:36-04:00  2020-08-19T15:32:15-04:00   \n",
       "\n",
       "              published_date material_type_facet kicker  \\\n",
       "0  2020-08-20T05:00:22-04:00                              \n",
       "1  2020-08-19T15:32:15-04:00                              \n",
       "\n",
       "                                           des_facet  \\\n",
       "0  [Discrimination, Black People, Race and Ethnic...   \n",
       "1  [Coronavirus (2019-nCoV), Antibodies, Boats an...   \n",
       "\n",
       "                                           org_facet per_facet  \\\n",
       "0  [American Academy of Pediatrics, American Medi...        []   \n",
       "1  [Hutchinson, Fred, Cancer Research Center, Abb...        []   \n",
       "\n",
       "                geo_facet                                         multimedia  \\\n",
       "0  [Southern States (US)]  [{'url': 'https://static01.nyt.com/images/2020...   \n",
       "1        [Seattle (Wash)]  [{'url': 'https://static01.nyt.com/images/2020...   \n",
       "\n",
       "                 short_url  \n",
       "0  https://nyti.ms/3ghMlzo  \n",
       "1  https://nyti.ms/3aFM0W4  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_stories = nyt.top_stories()\n",
    "\n",
    "# Get all the top stories from a specific category\n",
    "top_science_stories = nyt.top_stories(section = \"science\")\n",
    "pd.DataFrame(top_science_stories).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News API\n",
    "\n",
    "https://newsapi.org/docs/endpoints/everything\n",
    "\n",
    "> **Observation:** Conduct a(n ESG) supervised sentiment analysis on news articles by defining positive or negative keywords to search for. For example, searching for \"Microsoft scandal\" through News api mainly yields negative news about the firm. On the other hand, searching for \"Microsoft charity\" likely returns positive news about the firm. The simple assumption that every search term we define as negative is indeed negative. This defines the labels for a supervised prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok',\n",
       " 'totalResults': 38,\n",
       " 'articles': [{'source': {'id': 'cnn', 'name': 'CNN'},\n",
       "   'author': 'Mary Ilyushina, CNN',\n",
       "   'title': 'Putin critic Navalny hospitalized in Russia after suspected poisoning: spokeswoman - CNN',\n",
       "   'description': 'Russian opposition leader and outspoken Kremlin critic Alexei Navalny was placed on a ventilator and was unconscious in a hospital in Siberia Thursday after falling ill from suspected poisoning, his spokesperson said.',\n",
       "   'url': 'https://www.cnn.com/2020/08/20/europe/russia-navalny-hospitalized-intl-hnk/index.html',\n",
       "   'urlToImage': 'https://cdn.cnn.com/cnnnext/dam/assets/180123115306-alexey-navalny-january-2018-super-tease.jpg',\n",
       "   'publishedAt': '2020-08-20T06:21:00Z',\n",
       "   'content': 'Minsk, Belarus (CNN)Russian opposition leader and outspoken Kremlin critic Alexei Navalny was placed on a ventilator and was unconscious in a hospital in Siberia Thursday after falling ill from suspe… [+873 chars]'},\n",
       "  {'source': {'id': 'cnn', 'name': 'CNN'},\n",
       "   'author': 'Sol Han, CNN',\n",
       "   'title': \"Australia's Qantas says international flights 'unlikely' to resume before July 2021 - CNN\",\n",
       "   'description': 'Australian carrier Qantas Airways announced Thursday that it\\'s \"unlikely\" to resume international flights before July 2021, as it suffers heavy losses due to the coronavirus pandemic.',\n",
       "   'url': 'https://www.cnn.com/2020/08/19/business/qantas-international-flights/index.html',\n",
       "   'urlToImage': 'https://cdn.cnn.com/cnnnext/dam/assets/200819220315-qantas-airlines-0520-restricted-super-tease.jpg',\n",
       "   'publishedAt': '2020-08-20T04:36:00Z',\n",
       "   'content': 'Hong Kong (CNN Business)Australian carrier Qantas Airways announced Thursday that it\\'s \"unlikely\" to resume international flights before July 2021, as it suffers heavy losses due to the coronavirus p… [+1133 chars]'},\n",
       "  {'source': {'id': None, 'name': 'Slate Magazine'},\n",
       "   'author': 'Aaron Mak',\n",
       "   'title': 'The Most Gutting Part of the DNC’s Third Night - Slate',\n",
       "   'description': 'Stories from immigrants who risked their lives to come here, and of immigrants whose lives the Trump administration ripped apart.',\n",
       "   'url': 'https://slate.com/news-and-politics/2020/08/dnc-immigration-undocumented-trump.html',\n",
       "   'urlToImage': 'https://compote.slate.com/images/12e8166d-0a95-4e64-a72e-b6a6a9dbfc6a.jpeg?width=780&height=520&rect=999x666&offset=1x0',\n",
       "   'publishedAt': '2020-08-20T04:17:00Z',\n",
       "   'content': 'Jessica, Silvia, and Lucy Sanchez address the Democratic National Convention.DNCC via Getty Images\\r\\nEmotional, human-centered issue montages dominated the opening 30 minutes of the Democratic Nationa… [+3794 chars]'},\n",
       "  {'source': {'id': None, 'name': 'MarketWatch'},\n",
       "   'author': 'Mike Murphy',\n",
       "   'title': 'Dow futures down nearly 200 points after Fed minutes note concerns - MarketWatch',\n",
       "   'description': '',\n",
       "   'url': 'https://www.marketwatch.com/story/dow-futures-down-more-than-200-points-after-fed-minutes-note-concerns-2020-08-19',\n",
       "   'urlToImage': 'https://s.wsj.net/public/resources/MWimages/MW-GP644_MicroS_ZG_20180906154215.jpg',\n",
       "   'publishedAt': '2020-08-20T04:01:00Z',\n",
       "   'content': 'U.S. stock index futures sank Wednesday night, after stocks fell on Wall Street following Fed minutes that revealed concern over the economic outlook. As of midnight Eastern, Dow Jones Industrial Ave… [+838 chars]'},\n",
       "  {'source': {'id': 'fox-news', 'name': 'Fox News'},\n",
       "   'author': \"Andrew O'Reilly\",\n",
       "   'title': \"Warren touts Biden's 'really good plans,' says Trump 'failed miserably' on coronavirus - Fox News\",\n",
       "   'description': \"Sen. Elizabeth Warren – once one of Democratic presidential nominee Joe Biden's fiercest opponents during the primary season – praised the former vice president’s “really good plans” during a speech at the Democratic National Convention.\",\n",
       "   'url': 'https://www.foxnews.com/politics/warren-touts-bidens-really-good-plans-trump-failed',\n",
       "   'urlToImage': 'https://cf-images.us-east-1.prod.boltdns.net/v1/static/694940094001/f85d8cb7-b6d5-4cb0-bf8a-096576062ea9/eeb6b285-ae7b-4f52-bf33-6e08b35042d0/1280x720/match/image.jpg',\n",
       "   'publishedAt': '2020-08-20T03:53:04Z',\n",
       "   'content': \"Sen. Elizabeth Warren – once one of Democratic presidential nominee Joe Biden's fiercest opponents during the primary season – praised the former vice president’s “really good plans” during a speech … [+2587 chars]\"},\n",
       "  {'source': {'id': 'cnn', 'name': 'CNN'},\n",
       "   'author': 'Paula Hancocks, CNN',\n",
       "   'title': \"South Korea's latest church-linked coronavirus outbreak is turning into a battle over religious freedom - CNN\",\n",
       "   'description': 'A South Korean religious group at the center of a new coronavirus outbreak has been accused by the government of withholding key information and obstructing public health authorities in their fight against the pandemic.',\n",
       "   'url': 'https://www.cnn.com/2020/08/19/asia/south-korea-coronavirus-sarang-jeil-moon-intl-hnk/index.html',\n",
       "   'urlToImage': 'https://cdn.cnn.com/cnnnext/dam/assets/200819111451-south-korea-0818-coronavirus-02-super-tease.jpg',\n",
       "   'publishedAt': '2020-08-20T03:14:00Z',\n",
       "   'content': 'Seoul (CNN)A South Korean religious group at the center of a new coronavirus outbreak has been accused by the government of withholding key information and obstructing public health authorities in th… [+6335 chars]'},\n",
       "  {'source': {'id': 'fox-news', 'name': 'Fox News'},\n",
       "   'author': 'Paul Best',\n",
       "   'title': 'Michigan settles with Flint water crisis victims for more than $500 million: report - Fox News',\n",
       "   'description': 'The state of Michigan has settled with victims of the Flint water crisis for more than $500 million, and details of the settlement are expected Friday, Detroit News reports.',\n",
       "   'url': 'https://www.foxnews.com/us/michigan-settles-for-more-than-500-million-with-victims-of-flint-water-crisis-report',\n",
       "   'urlToImage': 'https://static.foxnews.com/foxnews.com/content/uploads/2020/01/flint-water-cropped.jpg',\n",
       "   'publishedAt': '2020-08-20T03:05:28Z',\n",
       "   'content': 'The state of Michigan has settled with victims of the Flint water crisis for more than $500 million, and details of the settlement are expected Friday, the Detroit News reports. \\r\\nRyan Jarvi, a spoke… [+2208 chars]'},\n",
       "  {'source': {'id': None, 'name': 'Eonline.com'},\n",
       "   'author': 'Cydney Contreras',\n",
       "   'title': \"Selling Sunset's Davina and Maya React to Chrissy Teigen Doubting Their Status as Realtors - E! NEWS\",\n",
       "   'description': \"Selling Sunset stars Davina Potratz and Maya Vander reveal why they're not offended Chrissy Teigen was questioning their careers as real estate agents.\",\n",
       "   'url': 'https://www.eonline.com/news/1180538/selling-sunsets-davina-and-maya-react-to-chrissy-teigen-doubting-their-status-as-realtors',\n",
       "   'urlToImage': 'https://akns-images.eonline.com/eol_images/Entire_Site/2020719/rs_600x600-200819185827-600_Maya_Vander_and_Davina_Potratz_mp_8.19.20.jpg?fit=around|1080:1080&output-quality=90&crop=1080:1080;center,top',\n",
       "   'publishedAt': '2020-08-20T02:54:13Z',\n",
       "   'content': 'All that to say Maya and Davina are by no means upset with Chrissy doubting their legitimacy as real estate agents.\\r\\n\"I\\'m definitely not offended. And I\\'m actually excited she watched the show again.… [+806 chars]'},\n",
       "  {'source': {'id': None, 'name': 'Entertainment Tonight'},\n",
       "   'author': 'Antoinette Bueno\\u200d',\n",
       "   'title': \"Britney Spears' Conservatorship: Dad Jamie's Role Remains Unchanged After She Asks Court to Drop Him - Entertainment Tonight\",\n",
       "   'description': 'The court documents also state that Britney Spears no longer wants to perform.',\n",
       "   'url': 'https://www.etonline.com/britney-spears-conservatorship-dad-jamies-role-remains-unchanged-after-she-asks-court-to-drop-him',\n",
       "   'urlToImage': 'https://www.etonline.com/sites/default/files/styles/max_1280x720/public/images/2020-08/gettyimages-539633370.jpg?h=c673cd1c&itok=NXFC0g1t',\n",
       "   'publishedAt': '2020-08-20T02:25:15Z',\n",
       "   'content': \"Britney Spears' requests on her long-standing conservatorship have gone unaddressed, days after the singer asked that her father, Jamie Spears, be removed as her conservator.\\r\\nIn a hearing on Wednesd… [+4058 chars]\"},\n",
       "  {'source': {'id': None, 'name': 'NPR'},\n",
       "   'author': '',\n",
       "   'title': '1 Dead In California Fire, As Lightning-Strike Fires Push Resources To Limit - NPR',\n",
       "   'description': 'A pilot was killed after he crashed while battling a blaze in Fresno County. Officials say \"a historic lightning siege\" has caused more than 367 new fires throughout California.',\n",
       "   'url': 'https://www.npr.org/2020/08/19/904086804/1-dead-in-california-fire-as-lightning-strike-fires-push-resources-to-limit',\n",
       "   'urlToImage': 'https://media.npr.org/assets/img/2020/08/19/ap_20232126020843_wide-518bf6095638a12ce0ab287cf6437617ad5a6034.jpg?s=1400',\n",
       "   'publishedAt': '2020-08-20T02:17:10Z',\n",
       "   'content': 'Embers burn along a hillside as the LNU Lightning Complex fires tear through unincorporated Napa County, Calif., on Tuesday. Fire crews across the region scrambled to contain dozens of wildfires spar… [+6379 chars]'},\n",
       "  {'source': {'id': None, 'name': 'Pitchfork'},\n",
       "   'author': 'Madison Bloom',\n",
       "   'title': 'Watch Ben Gibbard Play “Such Great Heights” for the United States Postal Service - Pitchfork',\n",
       "   'description': '“I’m going to play a song by the Postal Service and dedicate it to the Postal Service”',\n",
       "   'url': 'https://pitchfork.com/news/watch-ben-gibbard-play-such-great-heights-for-the-united-states-postal-service/',\n",
       "   'urlToImage': 'https://media.pitchfork.com/photos/5f3dc2bb4467b02428199223/16:9/w_1280,c_limit/Ben%2520Gibbard.png',\n",
       "   'publishedAt': '2020-08-20T00:58:13Z',\n",
       "   'content': 'Ben Gibbard performed two songs for the remote edition of the Democratic National Convention. Gibbard sang his Death Cab for Cutie track Northern Lights, as well as the Postal Service classic Such Gr… [+827 chars]'},\n",
       "  {'source': {'id': 'the-verge', 'name': 'The Verge'},\n",
       "   'author': 'Jay Peters',\n",
       "   'title': 'Here’s your best look yet at ZTE’s first smartphone with an under-display camera - The Verge',\n",
       "   'description': 'ZTE has shared a render of what the Axon 20 5G, its upcoming smartphone with an under-display camera, is expected to look like. The company also shared a render of what the display should look like when the screen is on, and there’s no visible camera — no hol…',\n",
       "   'url': 'https://www.theverge.com/2020/8/19/21376546/zte-smartphone-under-display-camera-axon-20-5g-renders-images',\n",
       "   'urlToImage': 'https://cdn.vox-cdn.com/thumbor/iAMpqxY-hgBrX5or10V_wCgXwS4=/0x14:690x375/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/21784916/ac80b11ely1ghw5lxuiajj21z4140e81__1_.jpg',\n",
       "   'publishedAt': '2020-08-20T00:33:03Z',\n",
       "   'content': 'And heres what the screen might look like turned on\\r\\nImage: ZTE\\r\\nZTE has already announced that it plans to launch the first mass-produced 5G-enabled smartphone with an under-display camera in China … [+1599 chars]'},\n",
       "  {'source': {'id': 'google-news', 'name': 'Google News'},\n",
       "   'author': None,\n",
       "   'title': 'NHL Highlights | First Round, Gm5: Coyotes @ Avalanche - Aug. 19, 2020 - NHL',\n",
       "   'description': None,\n",
       "   'url': 'https://news.google.com/__i/rss/rd/articles/CBMiK2h0dHBzOi8vd3d3LnlvdXR1YmUuY29tL3dhdGNoP3Y9LXo0Ti1TRzhIYUHSAQA?oc=5',\n",
       "   'urlToImage': None,\n",
       "   'publishedAt': '2020-08-20T00:31:56Z',\n",
       "   'content': None},\n",
       "  {'source': {'id': None, 'name': 'Yahoo Entertainment'},\n",
       "   'author': 'Shalise Manza Young',\n",
       "   'title': 'Masai Ujiri body-cam footage shows that no level of success can shield Black people from inequality - Yahoo Sports',\n",
       "   'description': 'The biggest moment of Ujiri’s professional career, marred forever by him being mistreated and manhandled.',\n",
       "   'url': 'https://sports.yahoo.com/masai-ujiri-bodycam-footage-raptors-president-alameda-county-234734235.html',\n",
       "   'urlToImage': 'https://s.yimg.com/uu/api/res/1.2/oZerBF2WRJOa0wbbwhwVvQ--~B/aD0yMzA0O3c9MzQ1NjtzbT0xO2FwcGlkPXl0YWNoeW9u/https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2020-08/550d8ca0-e26f-11ea-bfff-2ea98ddb32a4',\n",
       "   'publishedAt': '2020-08-19T23:47:00Z',\n",
       "   'content': 'The reminders never stop they just come with different names and different faces.\\r\\nOn Tuesday night, attorneys for Toronto Raptors president Masai Ujiri released the body-cam video from Alameda Count… [+4496 chars]'},\n",
       "  {'source': {'id': 'cnn', 'name': 'CNN'},\n",
       "   'author': 'Sandee LaMotte, CNN',\n",
       "   'title': '750 million genetically engineered mosquitoes approved for release in Florida Keys - CNN',\n",
       "   'description': 'A plan to release millions of genetically modified mosquitoes in 2021 has won final approval from authorities in the Florida Keys, despite the objection of many local residents and a coalition of environmental advocacy groups.',\n",
       "   'url': 'https://www.cnn.com/2020/08/19/health/gmo-mosquitoes-approved-florida-scn-wellness/index.html',\n",
       "   'urlToImage': 'https://cdn.cnn.com/cnnnext/dam/assets/190522114416-mosquito-stock-super-tease.jpg',\n",
       "   'publishedAt': '2020-08-19T23:38:00Z',\n",
       "   'content': '(CNN)A plan to release over 750 million genetically modified mosquitoes into the Florida Keys in 2021 and 2022 received final approval from local authorities, against the objection of many local resi… [+5209 chars]'},\n",
       "  {'source': {'id': 'the-wall-street-journal',\n",
       "    'name': 'The Wall Street Journal'},\n",
       "   'author': 'Preetika Rana',\n",
       "   'title': 'Airbnb Files Confidentially for IPO With SEC - The Wall Street Journal',\n",
       "   'description': 'Home-sharing giant’s plans to go public are a surprise turnaround after pandemic hurt bookings',\n",
       "   'url': 'https://www.wsj.com/articles/airbnb-files-confidentially-for-ipo-with-sec-11597870752',\n",
       "   'urlToImage': 'https://images.wsj.net/im-222950/social',\n",
       "   'publishedAt': '2020-08-19T23:35:00Z',\n",
       "   'content': 'Airbnb Inc. said Wednesday it confidentially filed paperwork with the Securities and Exchange Commission for an initial public offering, marking a surprising turnaround for a company whose business w… [+146 chars]'},\n",
       "  {'source': {'id': None, 'name': 'BBC News'},\n",
       "   'author': 'https://www.facebook.com/bbcnews',\n",
       "   'title': 'Mali coup: UN joins global condemnation of military takeover - BBC News',\n",
       "   'description': 'President Keïta was forced to resign after being detained by soldiers.',\n",
       "   'url': 'https://www.bbc.com/news/world-africa-53843526',\n",
       "   'urlToImage': 'https://ichef.bbci.co.uk/images/ic/1024x576/p08p06st.jpg',\n",
       "   'publishedAt': '2020-08-19T22:48:02Z',\n",
       "   'content': 'Media captionThe mutinying soldiers were cheered by crowds as they reached the capital Bamako on Tuesday\\r\\nThe United Nations has joined global condemnation of the military takeover in Mali, which saw… [+4947 chars]'},\n",
       "  {'source': {'id': None, 'name': 'MacRumors'},\n",
       "   'author': 'Juli Clover',\n",
       "   'title': 'Hundreds of iPhones With Fortnite Installed Flood eBay - MacRumors',\n",
       "   'description': 'Enterprising eBay sellers are hoping people who are desperate to play Fortnite will pay high prices for iPhones with the game installed, and there...',\n",
       "   'url': 'https://www.macrumors.com/2020/08/19/iphones-fortnite-ebay/',\n",
       "   'urlToImage': 'https://images.macrumors.com/article-new/2020/08/fortniteebay.jpg',\n",
       "   'publishedAt': '2020-08-19T22:18:00Z',\n",
       "   'content': 'Enterprising eBay sellers are hoping people who are desperate to play Fortnite will pay high prices for iPhones with the game installed, and there are currently hundreds of iPhone listings on eBay ad… [+2650 chars]'},\n",
       "  {'source': {'id': None, 'name': 'Daily Mail'},\n",
       "   'author': 'By George Stark For Dailymail.com',\n",
       "   'title': 'Sofia Richie shows off her incredible form playing tennis after Scott Disick split - Daily Mail',\n",
       "   'description': \"She certainly didn't appear to be down after it was claimed that her much older ex, Scott, 37, was the one who finished with her.\",\n",
       "   'url': 'https://www.dailymail.co.uk/tvshowbiz/article-8645017/Sofia-Richie-shows-incredible-form-playing-tennis-Scott-Disick-split.html',\n",
       "   'urlToImage': 'https://i.dailymail.co.uk/1s/2020/08/19/23/32151172-0-image-a-9_1597874989466.jpg',\n",
       "   'publishedAt': '2020-08-19T22:10:48Z',\n",
       "   'content': 'Sofia Richie is serving up a sporty new look after it was revealed ex-boyfriend Scott Disick has called time on their on-off relationship.\\r\\nDusting herself off from the reports, Sofia, 21, was pictur… [+3225 chars]'},\n",
       "  {'source': {'id': None, 'name': 'Phys.Org'},\n",
       "   'author': 'Science X staff',\n",
       "   'title': \"Kepler's supernova remnant: Debris from stellar explosion not slowed after 400 years - Phys.org\",\n",
       "   'description': \"Astronomers have used NASA's Chandra X-ray Observatory to record material blasting away from the site of an exploded star at speeds faster than 20 million miles per hour. This is about 25,000 times faster than the speed of sound on Earth.\",\n",
       "   'url': 'https://phys.org/news/2020-08-kepler-supernova-remnant-debris-stellar.html',\n",
       "   'urlToImage': 'https://scx2.b-cdn.net/gfx/news/hires/2020/keplerssuper.jpg',\n",
       "   'publishedAt': '2020-08-19T20:38:45Z',\n",
       "   'content': \"Astronomers have used NASA's Chandra X-ray Observatory to record material blasting away from the site of an exploded star at speeds faster than 20 million miles per hour. This is about 25,000 times f… [+6262 chars]\"}]}"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_api_key = open('news_api_key.txt', 'r') \n",
    "api_key = file_api_key.readlines()[0]\n",
    "\n",
    "url = ('http://newsapi.org/v2/top-headlines?'\n",
    "       'country=us&'\n",
    "       'apiKey={}'.format(api_key))\n",
    "\n",
    "response = requests.get(url)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
